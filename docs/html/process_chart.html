<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Valkka: Library architecture</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Valkka
   &#160;<span id="projectnumber">1.3.6</span>
   </div>
   <div id="projectbrief">OpenSource Video Management</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Library architecture </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>H264 decoding is done on the CPU, using the FFmpeg library. The final operation of interpolation from YUV bitmap into a RGB bitmap of correct (window) size is done on the GPU, using the openGL shading language.</p>
<p>This approach is a nice compromise as it takes some advantage of the GPU by offloading the (heavy) interpolation of (large) bitmaps.</p>
<p>One might think that it would be fancier to do the H264 decoding on the GPU as well, but this is a road to hell - forget about it.</p>
<p>Nv$dia for example, offers H264/5 decoding directly on their GPUs, but then you are dependent on their proprietary implementation, which means that:</p>
<ul>
<li>You'll never know how many H264 streams the proprietary graphics drivers is allowed to decode simultaneously. Such restraints are completely artificial and they are implemented so that you would buy a more expensive "specialized" card.</li>
<li>You'll never know what H264 "profiles" the proprietary driver supports.</li>
<li>There is no way you can even find out these things - no document exists that would reveal which chipset/card supports how many simultaneous H264 streams and which H264 profiles.</li>
</ul>
<p>So, if you're decoding only one H264 stream, then it might be ok to use proprietary H264 decoding on the GPU (but on the other hand, what's the point if it's only one stream..). If you want to do some serious parallel streaming (like here), invest on CPUs instead. <br  />
</p>
<p>Other possibilities to transfer the H264 decoding completely to the GPU are (not implemented in Valkka at the moment):</p>
<ul>
<li>Use Nvidia VDPAU (the API is open source) of the Mesa stack. In this case you must use X.org drivers for your GPU. <br  />
</li>
<li>Create a H264 decoder based on the OpenGL shading language. This would be cool (and demanding) project.</li>
</ul>
<p>In Valkka, concurrency in decoding and presenting various streams simultaneously is achieved using multithreading and mutex-protected fifos. This works roughly as follows:</p>
<pre class="fragment">Live555 thread (LiveThread)     FrameFifo       Decoding threads      OpenGLFrameFifo          OpenGLThread
                                                     
                                                                                              +-------------+ 
                                                                                              |             |
 +---------------------------+                                                                |interpolation|
 | rtsp negotiation          | -&gt; [FIFO] -&gt;      [AVThread] -&gt;                                |timing       |
 | frame composition         | -&gt; [FIFO] -&gt;      [AVthread] -&gt;          [Global FIFO] -&gt;      |presentation |
 |                           | -&gt; [FIFO] -&gt;      [AVthread] -&gt;                                |             |
 +---------------------------+                                                                |             |
                                                                                              +-------------+
</pre><p>A general purpose "mother" class <a class="el" href="classThread.html" title="A class for multithreading with a signaling system.">Thread</a> has been implemented (see <a class="el" href="group__threading__tag.html">multithreading</a>) for multithreading schemes and is inherited by:</p>
<ul>
<li><a class="el" href="classLiveThread.html" title="Live555, running in a separate thread.">LiveThread</a>, for connecting to media sources using the Live555 streaming library, see <a class="el" href="group__livethread__tag.html">livethread</a></li>
<li><a class="el" href="classAVThread.html" title="A thread consuming frames and feeding them to various encoders.">AVThread</a>, for decoding streams using the FFMpeg library and uploading them to GPU, see <a class="el" href="group__decoding__tag.html">decoding</a></li>
<li><a class="el" href="classOpenGLThread.html" title="This class does a lot of things:">OpenGLThread</a>, that handles direct memory access to GPU and presents the Frames, based on their timestamps, see <a class="el" href="group__openglthread__tag.html">opengl</a></li>
</ul>
<p>To get a rough idea how Live555 works, please see <a class="el" href="live555_page.html">Live555 primer</a> and <a class="el" href="group__live__tag.html">live555 bridge</a>. The livethread produces frames (class <a class="el" href="classFrame.html" title="Frame: An abstract queueable class.">Frame</a>), that are passed to mutex-protected fifos (see <a class="el" href="group__queues__tag.html">queues and fifos</a>).</p>
<p>Between the threads, frames are passed through series of "filters" (see <a class="el" href="group__filters__tag.html">available framefilters</a>). Filters can be used to modify the media packets (say, their timestamps for example) and to produce copying and redirection of the stream. Valkka library filters should not be confused with Live555 sink/source/filters nor with FFmpeg filters - which are completely different things.</p>
<p>For visualization of the media stream plumbings / graphs, we adopt the following notation which you should always use when commenting your python or cpp code:</p>
<pre class="fragment">() == Thread
{} == FrameFilter
[] == FrameFifo queue
</pre><p>To be more informative, we use:</p>
<pre class="fragment">(N. Thread class name: variable name)
{N. FrameFilter class name: variable name)
[N. FrameFifo class name: variable name]
</pre><p>A typical thread / framefilter graph would then look like this:</p>
<pre class="fragment">(1.LiveThread:livethread) --&gt; {2.TimestampFrameFilter:myfilter} --&gt; {3.FifoFrameFilter:fifofilter} --&gt; [4.FrameFifo:framefifo] --&gt;&gt; (5.AVThread:avthread) --&gt; ...
</pre><p> Which means that ..</p><ul>
<li>(1) <a class="el" href="classLiveThread.html" title="Live555, running in a separate thread.">LiveThread</a> reads the rtsp camera source, passes the frames to filter (2) that corrects the timestamp of the frame.</li>
<li>(2) passes the frames to a special filter (<a class="el" href="classFifoFrameFilter.html" title="Passes frames to a FrameFifo.">FifoFrameFilter</a>) which feeds a fifo queue (4).</li>
<li>(4) <a class="el" href="classFrameFifo.html" title="A thread-safe combination of a fifo (first-in-first-out) queue and an associated stack.">FrameFifo</a> is a class that handles a mutex-proteced fifo and a stack for frames</li>
</ul>
<p>The whole filter chain from (1) to (4) is simply a callback cascade. Because of this, the execution of <a class="el" href="classLiveThread.html" title="Live555, running in a separate thread.">LiveThread</a> (1) is blocked, until the callback chain has been completed. The callback chain ends to the "thread border", marked with "--&gt;&gt;". On the "other side" of the thread border, another thread is running independently.</p>
<p>Also, keep in mind the following rule:</p>
<ul>
<li>Processes read from mutex-protected fifos (base class for fifos is <a class="el" href="classFrameFifo.html" title="A thread-safe combination of a fifo (first-in-first-out) queue and an associated stack.">FrameFifo</a>)</li>
<li>Processes write into filters (base class <a class="el" href="classFrameFilter.html" title="The mother class of all frame filters!   FrameFilters are used to create &quot;filter chains&quot;.">FrameFilter</a>)</li>
</ul>
<p>In practice, <a class="el" href="classThread.html" title="A class for multithreading with a signaling system.">Thread</a> classes manage their own internal <a class="el" href="classFrameFifo.html" title="A thread-safe combination of a fifo (first-in-first-out) queue and an associated stack.">FrameFifo</a> and <a class="el" href="classFifoFrameFilter.html" title="Passes frames to a FrameFifo.">FifoFrameFilter</a> instances, and things become simpler: </p><pre class="fragment">* (1.LiveThread:livethread) --&gt; {2.TimestampFrameFilter:myfilter} --&gt;&gt; (3.AVThread:avthread) --&gt; ...
</pre><p>An input framefilter can be requested with AVThread::getFrameFifo()</p>
<p><a class="el" href="classLiveThread.html" title="Live555, running in a separate thread.">LiveThread</a>, <a class="el" href="classAVThread.html" title="A thread consuming frames and feeding them to various encoders.">AVThread</a> and <a class="el" href="classOpenGLThread.html" title="This class does a lot of things:">OpenGLThread</a> constructors take a parameter that defines the stack/fifo combination (<a class="el" href="structFrameFifoContext.html" title="Describes the stack structure and fifo behaviour for a FrameFifo.">FrameFifoContext</a>, <a class="el" href="structOpenGLFrameFifoContext.html" title="Describes the stack structure and fifo behaviour for an OpenGLFrameFifo.">OpenGLFrameFifoContext</a>).</p>
<p>In the case of <a class="el" href="classLiveThread.html" title="Live555, running in a separate thread.">LiveThread</a>, the API user passes a separate <a class="el" href="classFrameFilter.html" title="The mother class of all frame filters!   FrameFilters are used to create &quot;filter chains&quot;.">FrameFilter</a> per each requested stream to <a class="el" href="classLiveThread.html" title="Live555, running in a separate thread.">LiveThread</a>. That <a class="el" href="classFrameFilter.html" title="The mother class of all frame filters!   FrameFilters are used to create &quot;filter chains&quot;.">FrameFilter</a> then serves as a starting point for the filter chain. The last filter in the chain is typically <a class="el" href="classFifoFrameFilter.html" title="Passes frames to a FrameFifo.">FifoFrameFilter</a>, e.g. a filter that feeds the (modified/filtered) decoded frame to a fifo that is then being consumed by <a class="el" href="classAVThread.html" title="A thread consuming frames and feeding them to various encoders.">AVThread</a>.</p>
<p>For more details, refer to examples, doxygen documentation and the source code itself.</p>
<p>Remember that example we sketched in the github readme page? Using our notation, it would look like this:</p>
<pre class="fragment"> (1.LiveThread:livethread) --&gt; {2.TimestampFrameFilter:myfilter} 
                                  |
                                  +--&gt; {3.ForkFrameFilter:forkfilter}  
                                         |    |
                                         |    |
       through filters, to filesystem &lt;--+    +---&gt;&gt; (6.AVThread:avthread) ---------------------+
                                                                                                |
                                                                                                +--&gt; {7.ForkFrameFilter:forkfilter2}  
                                                                                                                 |    |                                                                                    
                                                                                                                 |    |
                                  (10.OpenGLThread:openglthread) &lt;&lt;----------------------------------------------+    +--&gt; .. finally, to analyzing process
                             feeds the video into various X-windoses</pre><ul>
<li>For the various FrameFilters, see <a class="el" href="group__filters__tag.html">available framefilters</a></li>
<li>For threads, see <a class="el" href="group__threading__tag.html">multithreading</a></li>
</ul>
<p>Some more miscellaneous details about the architecture:</p>
<ul>
<li><a class="el" href="classAVThread.html" title="A thread consuming frames and feeding them to various encoders.">AVThread</a> decoding threads both decode (with FFmpeg) and runs the uploading of the YUV bitmaps to the GPU. Uploading pixel buffer objects takes place in <a class="el" href="classOpenGLFrameFifo.html" title="A FrameFifo managed and used by OpenGLThread.">OpenGLFrameFifo</a>.</li>
<li>The <a class="el" href="classOpenGLThread.html" title="This class does a lot of things:">OpenGLThread</a> thread performs the final interpolation from YUV into RGB bitmap using the openGL shading language</li>
<li>Fifos are a combination of a fifo queue and a stack: each frame inserted into the fifo is taken from an internal reservoir stack. If no frames are left in the stack, it means overflow and the fifo/stack is resetted to its initial state</li>
<li>Reserving items for the fifo <em>beforehand</em> and placing them into a reservoir stack avoids constant memory (de)allocations that can become a bottleneck in multithreading schemes.</li>
<li>This way we also get "graceful overflow" behaviour: in the case the decoding threads or the OpenGL thread being too slow (i.e. if you have too many/heavy streams), the pipeline overflows in a controlled way.</li>
<li>For a complete walk-through from stream source to x window, check out <a class="el" href="pipeline.html">Code walkthrough: rendering</a> </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
